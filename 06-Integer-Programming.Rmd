---
title: "Getting Started with Integer Programming"
author: "Tim Anderson"
date: "9/25/2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library (magrittr, quietly = TRUE) #Used for pipes/dplyr
library (dplyr, quietly = TRUE)
library (ROI, quietly = TRUE)
library (ROI.plugin.glpk, quietly = TRUE)
library (ompr, quietly = TRUE)
library (ompr.roi, quietly = TRUE)
library (pander, quietly = TRUE)
```

# Getting Started with Integer Variables

Up until this point, we have always assumed that variables could take on fractional (or non-integer) values.  In other words, they were continuous variables.  Sometimes the values conveniently turned out to be integer-valued, in other cases, we would brush off the non-integer values of the results.

Allowing for integer values opens up many more important areas of applications as we will see.  

## Examples of Integrality

Let's look at two numerical examples.  The first shows a case where integrality makes little difference, the second where it has a major impact.

Unfortunately, there is no such thing as a free lunch-adding integrality can make problems much more computationally demanding. We will go through an example of how many optimization routines do integer optimization to demonstrate why it can be more difficult algorithmically even if looks trivially easy from the perspective of the change in the ompr function.

### Example of Integrality having Little Impact

Let's revisit the earlier example of producting chairs, desks, and tables.  Where we aded one extra hour of labor to the machining center.  The resulting LP is shown below.

$$
 \begin{split}
 \begin{aligned}
    \text{Max  }   & 20*Chairs+14*Desks+16*Tables \\
    \text{subject to } & 6*Chairs+2*Desks+4*Tables \leq 2000 \\
                       & 8*Chairs+6*Desks+4*Tables \leq 2000 \\
                       & 6*Chairs+4*Desks+8*Tables \leq 1441 \\
                       & 40*Chairs+25*Desks+25*Tables \leq 9600 \\
                       & Tables \leq 200 \\
                       & Chairs,  \; Desks, \; Tables \geq 0  
  \end{aligned}
  \end{split}
  (\#eq:IncMachiningHrs)
$$

We used the following implementation.  

```{r BaseModelCDT}

BaseModelCDT <- MIPModel() %>%
  add_variable(Chairs, type = "continuous", lb = 0) %>%
  add_variable(Desks, type = "continuous",lb = 0) %>%
  add_variable(Tables, type = "continuous", lb = 0) %>%
  
  set_objective(20*Chairs + 14*Desks + 16*Tables, "max") %>%
  
  add_constraint(6*Chairs + 2*Desks + 4*Tables <= 2000) %>% #fabrication
  add_constraint(8*Chairs + 6*Desks + 4*Tables <= 2000) %>% #assembly
  add_constraint(6*Chairs + 4*Desks + 8*Tables <= 1441) %>% #machining
  add_constraint(40*Chairs + 25*Desks + 25*Tables <= 9600) %>% #wood
  add_constraint(Tables <= 200) %>% #
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(BaseModelCDT)
  xchairs <- get_solution (BaseModelCDT, Chairs)
  xdesks  <- get_solution (BaseModelCDT, Desks)
  xtables <- get_solution (BaseModelCDT, Tables)

inc_mc_res  <- cbind(xchairs,xdesks,xtables,obj_val)
rownames(inc_mc_res) <- ""
pander(inc_mc_res,
       caption="Production Plan with Continuous variables")
```

In this case, the fractional value of *Chairs* would be only somewhat concerning.  We wouldn't actually ship a half of a chair to a customer-at least I hope not.  The difference between 162 and 163 is relatively small over a month of production.  This is a difference of less than 1% and none of the numbers specified in the model appear to be reported to more than two significant digits or this level of precision.  The result is that we could specify the answer as 162.5 and be satisfied that while it is our actual best guess or might reflect a chair half finished for the next month, it isn't a major concern.

For the sake of illustration, let's show how we would modify the model to be integers.  If we had wanted to modify the problem to force the amount of each item to be produced to be an integer value, we can modify our formulation and the implementation with only a few small changes.

In the formulation, we can replace the non-negativity requirement with a restriction that the variables are drawn from the set of non-negative integers.

$$
 \begin{split}
 \begin{aligned}
    \text{Max  }   & 20*Chairs+14*Desks+16*Tables \\
    \text{subject to } & 6*Chairs+2*Desks+4*Tables \leq 2000 \\
                       & 8*Chairs+6*Desks+4*Tables \leq 2000 \\
                       & 6*Chairs+4*Desks+8*Tables \leq 1441 \\
                       & 40*Chairs+25*Desks+25*Tables \leq 9600 \\
                       & Tables \leq 200 \\
                       & Chairs,  \; Desks, \; Tables \in \{0,1,2,3,...\}  
  \end{aligned}
  \end{split}
  (\#eq:IntegerProdPlan)
$$

The ompr implementation has a similar, straightforward change. In the declaration of variables (add_variable function), we simply set the type to be integer rather than continuous.

```{r IntegerModelCDT}

IntModelCDT <- MIPModel() %>%
  add_variable(Chairs, type = "integer", lb = 0) %>%
  add_variable(Desks, type = "integer",lb = 0) %>%
  add_variable(Tables, type = "integer", lb = 0) %>%
  
  set_objective(20*Chairs + 14*Desks + 16*Tables, "max") %>%
  
  add_constraint(6*Chairs + 2*Desks + 4*Tables <= 2000) %>% #fabrication
  add_constraint(8*Chairs + 6*Desks + 4*Tables <= 2000) %>% #assembly
  add_constraint(6*Chairs + 4*Desks + 8*Tables <= 1441) %>% #machining
  add_constraint(40*Chairs + 25*Desks + 25*Tables <= 9600) %>% #wood
  add_constraint(Tables <= 200) %>% #
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(IntModelCDT)
  xchairs <- get_solution (IntModelCDT, Chairs)
  xdesks  <- get_solution (IntModelCDT, Desks)
  xtables <- get_solution (IntModelCDT, Tables)

IntModelCDTres  <- cbind(xchairs,xdesks,xtables,obj_val)
rownames(IntModelCDTres) <- ""
pander(IntModelCDTres,
       caption="Production Plan with Integer Variables")
```

Notice that in this case, there was a small adjustment to the production plan and a small decrease to the optimal objective function value.  This is not always the case, sometimes the result can be unchanged.  In other cases, it may be changed in a very large way.  In others, the problem may in fact even become infeasible.

### Example of Integality having a Large Impact

Acme makes two products, let's refer to them as product 1 and 2.  Product 1 generates a profit of $2000 per product, requires one liter of surfactant for cleaning, 2.5 kilograms of high grade steel.

In contrast, each unit of Product 2 produced generates a higher profit of $3000 per product, requires 3.0 liters of surfactant, and 1.0 kilograms of high grade steel.  Acme has 8.25 liters of surfactant and 8.75 kilograms of high grade steel.  

Only completed producs are sellable, what should be Acme's production plan?

Formulating the optimization problem is similar to our earliest production planning problems.  Let's define $x_1$ to be the amount of product 1 to produce and $x_2$ to be the amount of product 2 to produce. 

$$
 \begin{split}
 \begin{aligned}
    \text{Max  }   & 2000 x_1 + 3000 x_2 \\
    \text{subject to } & 1.0 x_1 + 3.0 x_2 \leq 8.25 \\
                       & 2.5 x_1 + 1.0 x_2 \leq 8.75 \\
                       & x_1,  \; x_2 \geq 0  \\
                       & x_1,  \; x_2  \in \{0,1,2,3,...\}
  \end{aligned}
  \end{split}
  (\#eq:ILP)
$$

The last constraint cannot be solved directly strictly using linear programming.  It is instead referred to as an integer linear program or ILP.  

Again, we could try solving it with and without the imposition of the integrality constraint.


```{r SolveLPRelaxation0}

LPRelax <- MIPModel() %>%
  add_variable(xx1, type = "continuous", lb = 0) %>%
  add_variable(xx2, type = "continuous",lb = 0) %>%
  set_objective(2*xx1 + 3*xx2, "max") %>%
  add_constraint(1.0*xx1 + 3.0*xx2 <= 8.25) %>% #Surfactant
  add_constraint(2.5*xx1 + 1.0*xx2  <= 8.75) %>% #Steel
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(LPRelax)
  x1 <- get_solution (LPRelax, 'xx1')
  x2  <- get_solution (LPRelax, 'xx2')

acme_res_lp  <- cbind(x1,x2,obj_val)
colnames(acme_res_lp) <- list("x1", "x2", "Profit")
rownames(acme_res_lp) <- "LP Solution"
```

```{r SolveIP0}

IPSoln <- MIPModel() %>%
  add_variable(xx1, type = "integer", lb = 0) %>%
  add_variable(xx2, type = "integer",lb = 0) %>%
  set_objective(2*xx1 + 3*xx2, "max") %>%
  add_constraint(1.0*xx1 + 3.0*xx2 <= 8.25) %>% #Surfactant
  add_constraint(2.5*xx1 + 1.0*xx2  <= 8.75) %>% #Steel
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(IPSoln)
  x1 <- get_solution (IPSoln, 'xx1')
  x2  <- get_solution (IPSoln, 'xx2')

acme_res_ip  <- cbind(x1,x2,obj_val)
colnames(acme_res_ip) <- list("x1", "x2", "Profit")
rownames(acme_res_ip) <- "IP Solution"
pander(rbind(acme_res_lp,acme_res_ip),
       caption="Acme's Production Plan - Continuous vs. Integer")
```

Simply rounding down did not yield an optimal solution.
Notice that production of product 1 went down while product 2 went up.  The net impact was a profit reduction of almost _10%_.

## The Branch and Bound Algorithm

The simplicity of making the change in the model from continuous to integer variables hides or understates the complexity of what needs to be done to computationally to solve the optimization problem.  This small change can have major impacts on the computational effort needed to solve a problem.  Solving linear programs with tens of thousands of continuous variables is very quick and easy computationally.  Changing those same variables to general integers can make it *very* difficult. Why is this the case?

At its core, the basic problem is that the simplex method and linear programming solves a system of equations and unknowns (or variables).  It is trivial to solve one equation with one unknown such as $5x=7$.  It is only slighly harder to solve a system of two equations and two unknowns.  Doing three equations and three unknowns requires some careful algebra but is not too hard. In general, solving *n* equations and *n* unknowns is readily solveable.  On the other hand, none of this algebraic work will of solving for unknown variables can require that the variables take on integer values.  Even with only one equation and one unknown, *x* will only be integer for certain combinations of numbers in the above equation.  Specifically when the number on the right is a multiple of the number in front of *x*.  It gets even less likely to have an all integer solution as the number of equations and unknowns increase.  

Another way to visualize why integer solutions for general systems of inequalities is to think of the two equation and two unknown case.  Finding a solution is the same as finding where lines intersect in two dimensional space.  The odds of getting lucky and having the two lines intersect at an integer solution is small.  Even if we limit ourselves to a two dimeionsal space of the intersection occurs for x and y both being between 0 and 10, this means that there $11^2=121$ possible integer valued points in this space such as (0,0), (0,3), and (10,10).  In contrast, the set of all points, including non-integers, in this region includes all of the above points as well as (0,0.34) and (4.71, 7.89) among infinitely more.  The result is that if you think of this as a target shooting, the probability of finding an integer solution by blind luck is  $\frac{121}{\infty}\approx 0$. Certain structures for optimization problems will result in 

What we need to do is create an algorithm around the simplex method to accomplish this.  

A basic and common and approach often used for solving integer variable linear programming problems is called branch and bound.  We start with a solution that has presumably continuous valued variables.  We then branch (create subproblems) from here and add bounds (additional constraints) to rule out the possible fraction values.

### The LP Relaxation

To solve this using branch and bound, we *relax* the integrality requirements and solve what is called the LP Relaxation.  To do this, we simply remove the integrality requirement.

$$
 \begin{split}
 \begin{aligned}
    \text{Max  }   & 2000 x_1 + 3000 x_2 \\
    \text{subject to } & 1.0 x_1 + 3.0 x_2 \leq 8.25 \\
                       & 2.5 x_1 + 1.0 x_2 \leq 8.75 \\
                       & x_1,  \; x_2 \geq 0  \\
  \end{aligned}
  \end{split}
  (\#eq:LPRelaxation)
$$

This is a problem that we **can** solve using linear programming so let's go ahead do it!  Well, we already did so let's just review the results for what is now called the LP Relaxation because we are _relaxing_ the integrality requirements.

```{r SolveLPRelaxation}

pander(acme_res_lp,
       caption="Acme's Production Plan based on the LP Relaxation")
```

### Subproblem I
Alas, this production plan from the LP Relaxation is not feasible from the perspective of the original integer problem and requirement because it produces _2.769_ of  product 1 and _1.827_ of product 2.  If both variables had been integer we could have declared victory and been satisfied that we had easily found the optimal solution to integer programming problem so quickly.

Instead, we will need to proceed with the branch and bound process.  Since both of the variables in the LP relaxation have fractional values, we need to start by choosing which variable to branch off of.  Algorithmic researchers would focus on how to best pick a branch but for our purposes, it doesn't really matter so let's arbitrarily choose to branch on $x_1$.  

For the branch and bound algorithm, we want to include two subproblems that exclude the illegal value of $x_1=2.769$ as well as everything else between 2 and 3.  We  say that we are _branching_ on $x_1$ to create two subproblems.  The first subproblem (I) has an added constraint of $x_1\le 2.0$ and the other subproblem (II) has an added constraint of $x_1\ge 3.0$.  

$$
 \begin{split}
 \begin{aligned}
    \text{Max  }   & 2000 x_1 + 3000 x_2 \\
    \text{subject to } & 1.0 x_1 + 3.0 x_2 \leq 8.25 \\
                       & 2.5 x_1 + 1.0 x_2 \leq 8.75 \\
                       & x_1 \leq 2.0 \\
                       & x_1,  \; x_2 \geq 0  \\
  \end{aligned}
  \end{split}
  (\#eq:Sub1)
$$

```{r SolveLPSub1}

LPSubI <- MIPModel() %>%
  add_variable(xx1, type = "continuous", lb = 0) %>%
  add_variable(xx2, type = "continuous",lb = 0) %>%
  set_objective(2*xx1 + 3*xx2, "max") %>%
  add_constraint(1.0*xx1 + 3.0*xx2 <= 8.25) %>% #Surfactant
  add_constraint(2.5*xx1 + 1.0*xx2  <= 8.75) %>% #Steel
  add_constraint(xx1 <= 2.0) %>% #Bound for Subproblem 1
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(LPSubI)
  x1 <- get_solution (LPSubI, 'xx1')
  x2  <- get_solution (LPSubI, 'xx2')

LPSubI_res  <- cbind(x1,x2,obj_val)
rownames(LPSubI_res) <- ""
pander(LPSubI_res,
       caption="Acme's Production Plan based on the LP Subproblem I")
```

Looking over the results, we now get an integer value for $x_1$ but not for $x_2$. We repeat the same process by creating subproblems from subproblem I by branching off of $x_2$.  

### Subproblem III

Choosing which subproblem to examine next is one of the areas that large scale integer programming software and algorithms specialize and provide options. One way to think of it is to focus on searching down a branch and bound tree deeply or to search across the breadth of the tree.  For this example, let's go deep (we'll return to subproblem II later.)  

Since $x_2$ is now a non-integer solution, we will create branches with bounds (or constraints) on $x_2$ in the same manner as before.  Subproblem III has an added constraint of  $x_2 \le2.0$ and Subproblem IV has $x_2 \ge3.0$.  

To simplify the implementation, I can simply change the upper and lower bounds on variables rather than adding separate variables.  

```{r SolveLPSubIII}

LPSubIII <- MIPModel() %>%
  add_variable(xx1, type = "continuous", lb = 0, ub = 2) %>%
  add_variable(xx2, type = "continuous",lb = 0, ub = 2) %>%
  set_objective(2*xx1 + 3*xx2, "max") %>%
  add_constraint(1.0*xx1 + 3.0*xx2 <= 8.25) %>% #Surfactant
  add_constraint(2.5*xx1 + 1.0*xx2  <= 8.75) %>% #Steel
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(LPSubIII )
  x1 <- get_solution (LPSubIII , 'xx1')
  x2  <- get_solution (LPSubIII , 'xx2')

LPSubIII_res  <- cbind(x1,x2,obj_val)
rownames(LPSubIII_res) <- ""
pander(LPSubIII_res,
       caption="Acme's Production Plan based on the LP Subproblem III")
```

This results in integer values for both $x_1$ and $x_2$ so it is feasible with respect to integrality in addition to the production constraints.  It does generate less profit than the LP relaxation.  While it is feasible, it doesn't prove that it is optimal though.  We need to explore the other potential branches.  

### Subproblem IV

Next, let's look at Subproblem IV.  This problem adds the bound of $x_2\ge3.0$ to subproblem I.  Notice that in the MIPModel, the variable for $x_1$ has an upperbound (ub) of 2 in order to implement bounding constraint for subproblem I and the lower bound on $x_2$ of 3 in the variable declarations.

```{r SolveLPSubIV}

LPSubIV <- MIPModel() %>%
  add_variable(xx1, type = "continuous", lb = 0, ub = 2) %>%
  add_variable(xx2, type = "continuous",lb = 3) %>%
  set_objective(2*xx1 + 3*xx2, "max") %>%
  add_constraint(1.0*xx1 + 3.0*xx2 <= 8.25) %>% #Surfactant
  add_constraint(2.5*xx1 + 1.0*xx2  <= 8.75) %>% #Steel
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(LPSubIV )
  x1 <- get_solution (LPSubIV , 'xx1')
  x2  <- get_solution (LPSubIV , 'xx2')

LPSubIV_res  <- cbind(x1,x2,obj_val)
rownames(LPSubIV_res) <- ""
pander(LPSubIV_res,
       caption="Acme's Production Plan based on the LP Subproblem IV?")
```

At first glance, this looks okay but if you look more closely at the value of $x_2$, and the surfactant constraint, $x_1+3x_2\leq 9$, there isn't enough enough surfactant to make three units of the second product.  This means that by inspection we can see that this production plan is infeasible!  What is going on here?  

We should check the status of the solver before examining the result.  

```{r}
LPSubIV
```

The returned status value of this solved LP indicates that this tell us that subproblem IV is infeasible.  It still returned values that were used when it determined that the problem was infeasible which is why it gave the results in the previous table.  From here on out, it is good to check the status.  Note that it can be used as inline evaluated expression to simplay say was it feasbile or not?  Yes, it was `r LPSubIV$status`.  

### Subproblem II 

Now, we have searched down all branches or subproblems except for subproblem II.  Let's go back and do that problem.  We do that by simply adding one new bound to the LP Relaxation.  That is $x_1\ge 3.0$.

```{r SolveLPSubII}

LPSubII <- MIPModel() %>%
  add_variable(xx1, type = "continuous", lb = 3) %>%
  add_variable(xx2, type = "continuous",lb = 0) %>%
  set_objective(2*xx1 + 3*xx2, "max") %>%
  add_constraint(1.0*xx1 + 3.0*xx2 <= 8.25) %>% #Surfactant
  add_constraint(2.5*xx1 + 1.0*xx2  <= 8.75) %>% #Steel
  solve_model(with_ROI(solver = "glpk"))

  obj_val <- objective_value(LPSubII )
  x1 <- get_solution (LPSubII , 'xx1')
  x2  <- get_solution (LPSubII , 'xx2')

LPSubII_res  <- cbind(x1,x2,obj_val)

cat("Status of Subproblem II:",LPSubII$status)

rownames(LPSubII_res) <- ""
pander(LPSubII_res,
       caption="Acme's Production Plan based on the LP Subproblem II")
```

At this point, our first reaction is to breathe deeply and do the same branch and bound off of $x_2$.  If we step back and take note that the objective function value of 9.75, while optimal for this subproblem, it is less than what we found from a feasible solution to sub problem III. Given that adding countraints can't improve an objective function value, we can cleverly trim all branches below subproblem II.  

Given that we now no longer have any brances to explore, we can declare that we have found the optimal solution.  The optimal solution can now be declared to be what we found from Subproblem III.  

```{r}
pander(LPSubIII_res,
       caption="Acme's Optimal Production Plan based on the LP Subproblem III")
```

Before this, we could only say that it was feasible solution and candidate to be optimal since no better integer feasible solution had been found.

Let's put together the sequence of LPs solved.


```{r}
LPSubIII_res <- c("-", "-", "Infeasible")
BandB <- rbind(format(round(acme_res_lp,  3), nsmall = 3), 
               format(round(LPSubI_res,   3), nsmall = 3),
               LPSubIII_res, 
               format(round(LPSubIV_res,  3), nsmall = 3),
               format(round(LPSubII_res,  3), nsmall = 3))
rownames(BandB) <- list("LP Relaxtion", "LP Subproblem I", "LP Subproblem III",
                        "LP Subproblem IV", "LP Subproblem II")
pander(BandB, caption="Sequence of LPs followed by Branch and Bound")
```

### Computational Complexity of Integer Programming

As for computational complexity, this was a small problem with only two integer variables but it still required solving the LP Relaxation and four separate LP subproblems for a total of five linear programs in all.  As the number of variables and constraints increases, so do the number of LPs needed to typically finde a solution using branch and bound.  Small and medium size problems can generally be solved quickly but worst case scenarios have a combinatorial explosion.  

### Full Enumeration
Another approach to integer programming is full enumberation which means listing out all posible solutions and then determining if that solution is feasible and if so, what the objective function value is. Alas, this can result in a combinatorial explosion. For example, if a problem has 1000 non-negative integer variables each of which has an upper bound of 10, full enumeration would require listing $10^{1000}$ possible solutions.  Written out, the number of LPs would then be a 1 followed by a thousand zeros. This is far larger than the number of grains of sand on Earth (~$10^{19}$) or the number of stars in the universe (~$10^{19}$).  In fact this is much larger than the number of atoms in the universe (~$10^{80}$).  Needless to say explicit enumeration for large problems is not an option.  

### Branch and Bound in Practice

Worst case scenarios for Branch and Bound may approach that of full enumeration but in practice performs much better.  A variety of sophisticated alrogithmic extensions have been added by researchers over the years but solving largescale integer programming problems can still be quite difficult.

The Branch and Bound algorithm has the benefit that it will find the optimal solution.  Sometimes it will find it quickly, other times it may take a very long time.  

Also, if it is terminated early, it may report the best feasible solution found so far and a precise bound as to how much better an as yet unfound solution might be based on the best remaining open branch.  This difference between the best feasible solution found so far and the theoretically possible best solution to be found gives a gap that an analyst can set. This acceptable gap is sometimes referred to as a suboptimality tolerance factor.  In other words, what percentage of suboptimality is the analyst willing to accept for getting a solution more quickly. For example, a suboptimality tolerance factor of 10% would tell the software to terminate the branch and bound algorithm if a feasible solution is found and it is certain that regardless of how much more time is spent solving, it is impossible to improve upon this solution by more than 10%.

Note that if we had a wide enough suboptimality tolerance, say 30% and followed the branch for $x_1\ge3.0$ first rather than $x_1\le2.0$, we might have terminated with a suboptimal solution.

In practice, even small suboptimality tolerance factors like 1% can allow big problems to be solved more quickly and are often well with the margin of error for model data.  In other cases, organizations may be interested in finding *any* feasible solution to large, vexing problems.  

### Binary Variables and Logical Relations

Binary variables are a special case of general integer variables. Rather than variables taking on the value such as 46 and 973, acceptable values are limited to just 0 and 1.  This greatly reduces the possible search space for branch and bound since you know that in any branch, you will never branch on a single variable more than once.  On the other hand, with a large numbe of variables, the search space can still be very large.  If the previous case with 1000 variables were binary, a full enumeration list would rely on a list of $2^{1000}$ or one followed by about 300 zeros) possible solutions.  While better than the case of integers, it is still vastly more than the number of  atoms in the universe.

The important thing is is that binary variables give us a lot of rich opportunities to model complex, real world situations.

Examples include assigning prople to projects, go-no go decisions on projects, and much more.  

### In Class Exercise

Let's explore the impact of binary restrictions.

The world famous semiconductor company, Outtel has a choice of five major R&D projects.   
Develop processor architecture for autonomous vehicles (project A)
Next generation microprocessor architecture (project B)
Next generation process technology (project C)
New fabrication facility (project D)
New interconnect technology  (project E)

The key data is described as follows.  N is Net Present Value of the project factoring in costs.  E is the capital expenditures required for each project.  The company has $40 Billion in capital expenditures available.  Let's set up the data as matrices in R.  

```{r}
E <- matrix(c(12,24,20,8, 16),ncol=1,dimnames=list(LETTERS[1:5],"Exp"))

N <- matrix(c(2.0, 3.6, 3.2, 1.6, 2.8), ncol=1,dimnames=list(LETTERS[1:5],"NPV"))

pander (cbind(E,N), caption="Data for the Outtel In-Class Exercise")
```

#### Create the basic formulation as a mathematical model

These projects all carry their own expenses and engineering support.  There are limits to both the capital investment and engineering resources available.  Consider all of these project to be independent.  

#### Create and solve the basic naive formulation as a mathematical model

Formulate and solve a basic, naive model that allows project to repeated and partially completed.  Implement and solve your model.  What is the optimal decision?  Is this result surprising?  Does this make sense in terms of the application?  

#### Implementing a constraint to ensure no project is repeated

Now, let's explore one aspect of moving towards binary variables.  What constraint or constraints are needed to ensure no project is done more than once while allowing partial projects to stil be funded and incur both proportionate costs and benefits.  How does this solution compare to that of above?

#### Implementing a constraint to ensure no project is partially funded

What change is needed to prevent partial funding of projects.  How does this solution compare to that of above?  Can you envision a situation where it might make sense to have partially funded projects?  Could this be similar to corporate joint ventures where investments and benefits are shared across multiple entities?  

#### Logic Constraints

Now that effectively have binary constraints, let's explore the impact of logical restrictions with a series of separate scenarios.  In each of these cases, make sure that you implement the relationship as a linear relationship.  This means that you cannot use a function such as an "If-then", "OR", "Exclusive OR", or other relationship.  Furthermore, you can't multiply variables together or divide variables into variables.  

In each of the following sections create a linear relationship that models this situation.  

##### Implementing a Logic Constraint for chip architects (A & B)

Let's assume that projects A and B require the focused effort of the Outtel's top chip architects and Outtel has decided therefore that it is not possible to do both projects.  Therefore, they want to ensure that at most one of the two projects can be pursued.  What needs to be added to enforce this situation?

##### Implementing a Logic Constraint for interconnect technology (E)

Instead of the constraint on chip architects, let's consider the situation of the interconnect technology.  Assume that project E on interconnect technology would only provide strong benefit if a new architecture is also developed.  In other words, E can only be done if A or B is done.  Note that if both A and B are done, E will certainly have a use!

##### Implementing a Logic Constraint for manufacturing (C & D)

Outtel knows that staying aggressive in manufacturing is important in this competitive industry but that it is too risky to do too much at once from manufacturing perspective.  The result is that Outtel want to ensure that exactly one major manufactuing initiative (C or D) must be done.  In other words, project C or project D must be done but not both.  

##### Solve for each of the above logic cases and discuss how the solutions compare

Solve for the base case and then show the results of just each constraint at once.  Combine the results into a single pander table.  Discuss the results.  

##### Consider full enumeration

When projects can be neither partially funded nor repeated, how many candidate solutions would there be by full enumeration?  Can you list them out?  

## Exercise

Take a look at Dirk Schumacher's vignette for "Course Planning".  https://dirkschumacher.github.io/ompr/articles/problem-course-assignment.html 

Dirk is the author of ompr and has a nice collection of vignettes.  

Consider the application of senior design capstone projets where a class of 32 students is going to be divided up to work on 6 projects.  Outside sponsors pitch topics and then each student of the 32 students gives a score of 0 to 10 to indicate how interested they are in the topic.  Using the student project preferences, you want to assign students to the projects that they are most interested in.  

You may use Dirk's vignette as a starting point to build your own model for assigning students to projects based on their preferences.   Projects can have no more than 6 people on a single capstone project and every student needs to be assigned to a project.

Student preferences can be loaded from the comma separated file as shown below or typed in.

```{r}
studentpref<-read.csv(file="HW5data.csv")

pander (studentpref, caption="Student to Project Preferences")
```

Build and solve an appropriate model.  Be sure to describe your formulation and discuss the results.

### Challenge Question

Can this problem ever be in feasible if the number of students is less than 6 times the number of projects?  Why or why not?

## Fixed Charge Models

Next week we will look at larger scale integer programming problems and a common issue to model of fixed charge.  

Fixed charge models are a special case of integer programming models where situations where product cost has a fixed cost component and a marginal (per unit) cost component.

A common example of this is when a machine must be setup before any production can occur.  For example let's assume that desk, table, and bookcase production would each require fixtures for production with varying cost, say $ \$800$, $ \$600$, and $ \$500$ respectively.  How would this affect your decision to produce items?  

One option is to pay for manufacturing setups of all three products.  At $ \$1900$, this eliminates the potential option of choosing to make only two or three products.  
(Create a model....)

Now, We could introduce a decision variable to represent the "go-no go" decision for each product.  If we now solve for this case, let's examine the solution.

What we can see is that we are producing some of xxxx and yyy but we don't have any fixtures for producing these products.  

What we need to do is connect the decision variables of how much of a product to make and whether we make any of that product.  

We do that by connecting the two decision variables for each of the products.  We will leave that as a challenge to be talked about more next week.  
